# WORK IN PROGRESS
services:
  ollama-tg:
    build:
      context: .
      dockerfile: Dockerfile.ollama-tg
    container_name: ollama-tg
    restart: on-failure
    env_file:
      - ./.env
    volumes:
      - ollama-tg:/code/  # Mounting a volume for SQLite database

  ollama-api:
    image: ollama/ollama:latest
    container_name: ollama-server
    volumes:
      - ./ollama:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: on-failure

  faster-whisper:
    build:
      context: .
      dockerfile: Dockerfile.faster-whisper
    environment:
      - MODEL_SIZE=small  # or medium, large-v2, etc.
      - DEVICE=cpu  # change to cuda if using GPU
      - COMPUTE_TYPE=int8
    volumes:
      - whisper-models:/root/.cache/huggingface/hub
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: on-failure

volumes:
  ollama-tg:
  whisper-models:
